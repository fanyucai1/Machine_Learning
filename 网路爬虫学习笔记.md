     
1. 防止IP被封的方法，伪造浏览器登陆

        Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)
        Mozilla/5.0 (iPhone; CPU iPhone OS 7_0 like Mac OS X) AppleWebKit/537.51.1 (KHTML, like Gecko) Version/7.0 Mobile/11A465 Safari/9537.53 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)
        Mozilla/5.0 (Windows Phone 8.1; ARM; Trident/7.0; Touch; rv:11.0; IEMobile/11.0; NOKIA; Lumia 530) like Gecko (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)

2. 寻找代理服务器IP地址，防止同一个IP发起过多请求而被封IP

        免费的资源很多：https://www.kuaidaili.com/ops/proxylist/1/，在选择的时候一定要验证其有效性，免费的都有一定的时效性
        
        代理服务器有http有https两种需要仔细区分，还有在选择的时候要选择高匿名以及响应速度快的
        
        如果你可以翻墙还可以推荐给你一个免费的代理IP，来自全世界的http://free-proxy.cz/zh/proxylist/country/all/https/ping/level1，我在爬取cosmic的时候有用到

3. python模块
    
    Requests        https://2.python-requests.org//zh_CN/latest/index.html
    
        r = requests.get('https://api.github.com/user', auth=('user', 'pass'),verify=False)
        判断是否返回正常则有：
        r.status_code==200
        解析：
        r.txt
        r.json()

    Beautiful Soup  https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html#id66
   
4. 
    代码示例一：cosmicID的状态：Yes（e.g:COSM6918278）No(e.g:COSM6475151)SNP(e.g:COSM6972367)

        import requests
        from bs4 import BeautifulSoup
        import re
        id=input("please input COSMIC ID(e.g:COSM3677745):")
        pattern=re.compile(r'\d+')
        num=pattern.findall(id)
        url="https://cancer.sanger.ac.uk/cosmic/mutation/overview?genome=37&id=%s" %(num[0])
        res=requests.get(url,proxies={"https":"https://163.204.244.194:9999"})
        ret = res.text
        soup=BeautifulSoup(ret,'html.parser')
        dbsnp=soup.find_all(text=re.compile("has been flagged as a SNP."))
        dt = soup.find_all('dt')
        dd = soup.find_all('dd')
        for i in range(len(dt)):
            if dt[i].string == "Ever confirmed somatic?":
                print("%s\t%s" % (id, dd[i].string))
        if dbsnp!=[]:
            print("%s\tSNP" % (id))
            
    代码示例二:可根据bed文件爬取对应的cosmicID的状态

        import requests
        import urllib3
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        requests.adapters.DEFAULT_RETRIES =10#增加重连次数
        from bs4 import BeautifulSoup
        import re
        import time
        import random
        import os
        from multiprocessing import Process, Pool
        #############################
        site={}
        bedfile=["DHS-3501Z.roi.bed","panel_27.bed","panel_599.bed","TST500C_manifest.bed"]
        for i in bedfile:
            infile=open(i,"r")
            for line in infile:
                line=line.strip()
                array=line.split()
                for k in range(int(array[1]),int(array[2])+1):
                    tmp=array[0]+"_"+str(k)
                    site[tmp]=1
            infile.close()
        print("There total %s sites" %(len(site)))
        ##############################在请求头中把User-Agent设置成浏览器中的User-Agent，来伪造浏览器访问
        user_agents = ['Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1',
                       'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50',
                       'Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11',
                       "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 UBrowser/4.0.3214.0 Safari/537.36",
                       "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; QQBrowser/7.0.3698.400)",
                       "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5",
                       "Mozilla/5.0 (SymbianOS/9.4; Series60/5.0 NokiaN97-1/20.0.019; Profile/MIDP-2.1 Configuration/CLDC-1.1) AppleWebKit/525 (KHTML, like Gecko) BrowserNG/7.1.18124"]
        vcf="all_COSMICID.txt"
        proxy_type=['http','https']
        #proxy_http=['117.90.0.225:9000']
        proxy_https=['166.111.82.202:8118','60.13.42.107:9999','119.57.105.25:53281']
        dict={}
        if os.path.exists("cosmic.tsv"):
            outfile=open("cosmic.tsv","r")
            for line in outfile:
                line=line.strip()
                array=line.split()
                dict[array[0]]=1
            outfile.close()
        ###############################
        numID=[]
        infile=open(vcf,"r")
        SNP={}
        for line in infile:
            line=line.strip()
            if not line.startswith("#"):
                array=line.split("\t")
                p1=re.compile(r'SNP')
                a=p1.findall(array[-1])
                tmp="chr"+array[0]+"_"+array[1]
                if tmp in site:
                    p2=re.compile(r'(\d+)')
                    id=p2.findall(array[2])
                    if not array[2] in dict:
                        if a==[]:
                            numID.append(id[0])
                        else:
                            outfile = open("cosmic.tsv", "a+")
                            outfile.write("COSM%s\tSNP\n" % (id[0]))
                            outfile.close()
                            continue
        infile.close()
        print("Total %s entry in COSMIC"%(len(numID)))
        def run(id):
            outfile = open("cosmic.tsv", "a+")
            url = 'https://cancer.sanger.ac.uk/cosmic/mutation/overview?genome=37&id=%s' % (id)
            headers = {'User-Agent': random.choice(user_agents)} # 随机选择一个User-Agent
            #if random.choice(proxy_type)=='http':
            #    ip={'http':'http://'+random.choice(proxy_http)}
            #else:
            ip = {'https': 'https://' + random.choice(proxy_https)}
            s = requests.session()
            s.keep_alive = False  # 关闭多余连接
            try:
                res = s.get(url, headers=headers, verify=False,proxies=ip)
                ret = res.text
                soup = BeautifulSoup(ret, 'html.parser')
                dbsnp = soup.find_all(text=re.compile("has been flagged as a SNP."))
                dt = soup.find_all('dt')
                dd = soup.find_all('dd')
                outfile = open("cosmic.tsv", "a+")
                for i in range(len(dt)):
                    if dt[i].string == "Ever confirmed somatic?":
                        outfile.write("COSM%s\t%s\n" % (id, dd[i].get_text()))
                        outfile.close()
                        print("%s id done." % (id))
                        continue
                if dbsnp != []:
                    outfile.write("COSM%s\tSNP\n" % (id))
                    outfile.close()
                    print("%s id done." % (id))
            except:
                print("%s id erro."%(id))
                outfile.close()
        start=time.time()
        pool = Pool(processes=200)
        pool.map(run, numID)
        end=time.time()
        print("Elapse time is %g seconds" %(end-start))
    
    示例三：爬取OMIM数据库，测试首先保证你可以打开https://www.omim.org/entry/111600，否则请翻墙，爬取对应的OMIM ID与表型的信息

        import requests
        import urllib3
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        from bs4 import BeautifulSoup
        import random
        import re
        import os
        import time
        from multiprocessing import Process, Pool
        #######################################
        dict={}
        if os.path.exists("omim.tsv"):
            infile=open("omim.tsv","r")
            for line in infile:
                line=line.strip()
                array=line.split()
                dict[array[0]]=1
            infile.close()
        else:
            outfile = open("omim.tsv", "w")
            outfile.write("#MIM_Number\tLocation\tPhenotype\tPhenotype_MIM_number\tInheritance\tPhenotype_mapping_key\n")
            outfile.close()
        #######################################
        id=[]
        infile=open("mim2gene.txt","r")#https://www.omim.org/static/omim/data/mim2gene.txt(2019-7-3)
        for line in infile:
            if not line.startswith("#"):
                line=line.strip()
                array=line.split()
                if not array[0] in dict:
                    id.append(array[0])
        infile.close()
        #######################################
        #############################在请求头中把User-Agent设置成浏览器中的User-Agent，来伪造浏览器访问
        def run(omim_id):
            user_agents =['Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)',
                          'Mozilla/5.0 (iPhone; CPU iPhone OS 7_0 like Mac OS X) AppleWebKit/537.51.1 (KHTML, like Gecko) Version/7.0 Mobile/11A465 Safari/9537.53 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)',
                          'Mozilla/5.0 (Windows Phone 8.1; ARM; Trident/7.0; Touch; rv:11.0; IEMobile/11.0; NOKIA; Lumia 530) like Gecko (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)'
                          ]#https://www.bing.com/webmaster/help/which-crawlers-does-bing-use-8c184ec0
            #ip=["165.22.186.43:8118"]
            url="https://omim.org/entry/%s"%(omim_id)
            #proxy={"https":"https://"+random.choice(ip)}
            headers = {'User-Agent': random.choice(user_agents)}
            s = requests.session()
            s.keep_alive = False
            #res=requests.get(url,headers=headers,proxies=proxy)
            res = requests.get(url, headers=headers)
            ret=res.text
            soup=BeautifulSoup(ret,'html.parser')
            outfile = open("omim.tsv", "a+")
            try:
                ########################################table
                Pos=soup.table.tbody.find_all('tr')#####判断表格有多少行
                #########################################Location
                Location=soup.table.tbody.td.span.a.text
                Location = Location.strip()
                ##########################################Phenotype
                Phenotype = []
                num=0
                for i in Pos:
                    num+=1
                    if num==1:
                        str=i.find_all('span',limit=2)
                        Phenotype.append(str[1].string.strip())
                    else:
                        str=i.td.span.string.strip()
                        if str:
                            Phenotype.append(str)
                ###########################################Phenotype_MIM_number
                Phenotype_MIM_number=[]
                for i in Pos:
                    str=i.find('a',href=re.compile("entry"))
                    if str:
                        Phenotype_MIM_number.append(str.string)
                    else:
                        Phenotype_MIM_number.append("_")
                ###########################################
                Inheritance = []
                key = []
                for i in Pos:
                    str=i.find_all('abbr')
                    tmp=""
                    for j in str:
                        tmp+=","
                        tmp+=j.string
                    array=re.split(r'(\d+)',tmp)
                    real_key=0
                    real_Inheritance=0
                    for i in array:
                        p1 = re.compile(r'[A-Za-z]')
                        p2 = re.compile(r'(\d+)')
                        a = p1.findall(i)
                        b = p2.findall(i)
                        if i.strip(",") != "":
                            if a != []:
                                Inheritance.append(i.strip(","))
                                real_Inheritance = 1
                            if b != []:
                                key.append(i.strip(","))
                                real_key = 1
                    if real_key==0:
                        key.append("_")
                    if real_Inheritance==0:
                        Inheritance.append("_")
                for i in range(len(Phenotype)):
                    outfile.write(
                        "%s\t%s\t%s\t%s\t%s\t%s\n" % (omim_id,Location, Phenotype[i], Phenotype_MIM_number[i], Inheritance[i], key[i]))
                outfile.close()
            except:
                print(omim_id)
                outfile.write("%s\t_\t_\t_\t_\t_\n"%(omim_id))
                outfile.close()
        if __name__=="__main__":
            for i in id:
               run(i)
               time.sleep(3)         