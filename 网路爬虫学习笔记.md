     
1. 防止IP被封的方法，伪造浏览器登陆

        Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)
        Mozilla/5.0 (iPhone; CPU iPhone OS 7_0 like Mac OS X) AppleWebKit/537.51.1 (KHTML, like Gecko) Version/7.0 Mobile/11A465 Safari/9537.53 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)
        Mozilla/5.0 (Windows Phone 8.1; ARM; Trident/7.0; Touch; rv:11.0; IEMobile/11.0; NOKIA; Lumia 530) like Gecko (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)

2. 寻找代理服务器IP地址，防止同一个IP发起过多请求而被封IP

        免费的资源很多：https://www.kuaidaili.com/ops/proxylist/1/，在选择的时候一定要验证其有效性，免费的都有一定的时效性
        
        代理服务器有http有https两种需要仔细区分，还有在选择的时候要选择高匿名以及响应速度快的

3. python模块
    
    Requests        https://2.python-requests.org//zh_CN/latest/index.html
    
        r = requests.get('https://api.github.com/user', auth=('user', 'pass'),verify=False)
        判断是否返回正常则有：
        r.status_code==200
        解析：
        r.txt
        r.json()

    Beautiful Soup  https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html#id66
   
4. 
    代码示例一：

        import requests
        from bs4 import BeautifulSoup
        import re
        id=input("please input COSMIC ID(e.g:COSM3677745):")
        pattern=re.compile(r'\d+')
        num=pattern.findall(id)
        url="https://cancer.sanger.ac.uk/cosmic/mutation/overview?genome=37&id=%s" %(num[0])
        res=requests.get(url,proxies={"https":"https://163.204.244.194:9999"})
        ret = res.text
        soup=BeautifulSoup(ret,'html.parser')
        dbsnp=soup.find_all(text=re.compile("has been flagged as a SNP."))
        dt = soup.find_all('dt')
        dd = soup.find_all('dd')
        for i in range(len(dt)):
            if dt[i].string == "Ever confirmed somatic?":
                print("%s\t%s" % (id, dd[i].string))
        if dbsnp!=[]:
            print("%s\tSNP" % (id))
            
    代码示例二:

        import requests
        import urllib3
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        requests.adapters.DEFAULT_RETRIES =10#增加重连次数
        from bs4 import BeautifulSoup
        import re
        import time
        import random
        import os
        from multiprocessing import Process, Pool
        #############################
        site={}
        bedfile=["DHS-3501Z.roi.bed","panel_27.bed","panel_599.bed","TST500C_manifest.bed"]
        for i in bedfile:
            infile=open(i,"r")
            for line in infile:
                line=line.strip()
                array=line.split()
                for k in range(int(array[1]),int(array[2])+1):
                    tmp=array[0]+"_"+str(k)
                    site[tmp]=1
            infile.close()
        print("There total %s sites" %(len(site)))
        ##############################在请求头中把User-Agent设置成浏览器中的User-Agent，来伪造浏览器访问
        user_agents = ['Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1',
                       'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50',
                       'Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11',
                       "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 UBrowser/4.0.3214.0 Safari/537.36",
                       "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; .NET4.0E; QQBrowser/7.0.3698.400)",
                       "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5",
                       "Mozilla/5.0 (SymbianOS/9.4; Series60/5.0 NokiaN97-1/20.0.019; Profile/MIDP-2.1 Configuration/CLDC-1.1) AppleWebKit/525 (KHTML, like Gecko) BrowserNG/7.1.18124"]
        vcf="all_COSMICID.txt"
        proxy_type=['http','https']
        #proxy_http=['117.90.0.225:9000']
        proxy_https=['166.111.82.202:8118','60.13.42.107:9999','119.57.105.25:53281']
        dict={}
        if os.path.exists("cosmic.tsv"):
            outfile=open("cosmic.tsv","r")
            for line in outfile:
                line=line.strip()
                array=line.split()
                dict[array[0]]=1
            outfile.close()
        ###############################
        numID=[]
        infile=open(vcf,"r")
        SNP={}
        for line in infile:
            line=line.strip()
            if not line.startswith("#"):
                array=line.split("\t")
                p1=re.compile(r'SNP')
                a=p1.findall(array[-1])
                tmp="chr"+array[0]+"_"+array[1]
                if tmp in site:
                    p2=re.compile(r'(\d+)')
                    id=p2.findall(array[2])
                    if not array[2] in dict:
                        if a==[]:
                            numID.append(id[0])
                        else:
                            outfile = open("cosmic.tsv", "a+")
                            outfile.write("COSM%s\tSNP\n" % (id[0]))
                            outfile.close()
                            continue
        infile.close()
        print("Total %s entry in COSMIC"%(len(numID)))
        def run(id):
            outfile = open("cosmic.tsv", "a+")
            url = 'https://cancer.sanger.ac.uk/cosmic/mutation/overview?genome=37&id=%s' % (id)
            headers = {'User-Agent': random.choice(user_agents)} # 随机选择一个User-Agent
            #if random.choice(proxy_type)=='http':
            #    ip={'http':'http://'+random.choice(proxy_http)}
            #else:
            ip = {'https': 'https://' + random.choice(proxy_https)}
            s = requests.session()
            s.keep_alive = False  # 关闭多余连接
            try:
                res = s.get(url, headers=headers, verify=False,proxies=ip)
                ret = res.text
                soup = BeautifulSoup(ret, 'html.parser')
                dbsnp = soup.find_all(text=re.compile("has been flagged as a SNP."))
                dt = soup.find_all('dt')
                dd = soup.find_all('dd')
                outfile = open("cosmic.tsv", "a+")
                for i in range(len(dt)):
                    if dt[i].string == "Ever confirmed somatic?":
                        outfile.write("COSM%s\t%s\n" % (id, dd[i].get_text()))
                        outfile.close()
                        print("%s id done." % (id))
                        continue
                if dbsnp != []:
                    outfile.write("COSM%s\tSNP\n" % (id))
                    outfile.close()
                    print("%s id done." % (id))
            except:
                print("%s id erro."%(id))
                outfile.close()
        start=time.time()
        pool = Pool(processes=200)
        pool.map(run, numID)
        end=time.time()
        print("Elapse time is %g seconds" %(end-start))